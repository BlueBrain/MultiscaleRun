include:
  - project: hpc/gitlab-pipelines
    file:
      - spack-build-components.gitlab-ci.yml
      - bbp-gitlab-access.yml

default:
  tags: [bb5_map]

variables:
  # this it taken into account only if STEPS_USE_MODULE==0
  STEPS_BRANCH: master
  STEPS_USE_MODULE: 1
  # this it taken into account only if PY_NEURODAMUS_USE_MODULE==0
  PY_NEURODAMUS_BRANCH: main
  PY_NEURODAMUS_USE_MODULE: 1
  # this it taken into account only if PY_NEURODAMUS_USE_MODULE==0
  NEURODAMUS_NEOCORTEX_BRANCH: main
  NEURODAMUS_NEOCORTEX_USE_MODULE: 1



workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "push"
      when: never
    - when: always

spack_setup:
  extends: [.spack_setup_ccache]
  before_script:
    - SPACK_BRANCH=develop

.build:
  extends: [.spack_build]
  variables:
    bb5_ntasks: 2   # so we block 16 cores
    bb5_cpus_per_task: 8 # ninja -j {this}
    bb5_memory: 76G # ~16*384/80

setup_steps:
  extends: [.build]
  variables:
    SPACK_PACKAGE: steps
    SPACK_PACKAGE_SPEC: ^petsc+int64+mpi
  rules:
    - if: $STEPS_USE_MODULE == "0" && $CI_PIPELINE_SOURCE == "merge_request_event"

setup_neurodamus_neocortex:
  extends: [.build]
  variables:
    SPACK_PACKAGE: neurodamus-neocortex
    SPACK_PACKAGE_SPEC: +ngv+metabolism
  rules:
    - if: $NEURODAMUS_NEOCORTEX_USE_MODULE == "0" && $CI_PIPELINE_SOURCE == "merge_request_event"

.custom_build:
  stage: build
  variables:
    bb5_ntasks: 2   # so we block 16 cores
    bb5_cpus_per_task: 8 # ninja -j {this}
    bb5_memory: 76G # ~16*384/80
    IS_SPACK_UPDATED: 1
  artifacts:
    when: always
    paths:
      - "${envfile}.env"
    reports:
      dotenv:
        - "${envfile}.env"
  script:
    - !reference [ .bbp_gitlab_access, script ]
    - source .ci/setup.sh
  

setup_bloodflow:
  extends: [.custom_build]
  needs:
    - spack_setup
  variables:
    setup_file: .setup_bloodflow.sh
    envvars: "envvars=(BLOODFLOW_PATH)"
    envfile: bloodflow_envs

setup_spackenv:
  extends: [.custom_build]
  needs:
    - spack_setup
    - job: setup_neurodamus_neocortex
      optional: true
    - job: setup_steps
      optional: true
  variables:
    setup_file: .setup_spackenv.sh
    envvars: "envvars=(SPACKENV_PATH)"
    envfile: spack_envs

setup_python_venv:
  extends: [.custom_build]
  needs:
    - spack_setup
    - setup_bloodflow
  variables:
    setup_file: .setup_python_venv.sh
    envvars: "envvars=(PYTHON_VENV_PATH)"
    envfile: python_venv_envs


setup_julia:
  extends: [.custom_build]
  needs:
    - spack_setup
    - setup_python_venv
  variables:
    setup_file: .setup_julia.sh
    envvars: "envvars=(JULIA_DEPOT_PATH JULIA_PROJECT)"
    envfile: julia_envs
  cache:
    - key: julia_cache3
      paths: 
        - ${JULIA_DEPOT_PATH}
        - ${JULIA_PROJECT}

.test:
  stage: test
  needs:
    - spack_setup
    - setup_spackenv
    - setup_julia
    - setup_python_venv
    - job: setup_neurodamus_neocortex
      optional: true
    - job: setup_steps
      optional: true
    - setup_bloodflow
  variables:
    bb5_exclusive: "full"
    bb5_constraint: cpu
    bb5_memory: 0
    bb5_cpus_per_task: 2
    OMP_NUM_THREADS: 1

pytests:
  extends: [.test]
  script:
  # this hangs if called on the folder
    - source .ci/load.sh
    - python -mpytest tests/pytests/test_bloodflow.py
    - python -mpytest tests/pytests/test_metabolism.py
    - python -mpytest tests/pytests/test_neurodamus.py
    - python -mpytest tests/pytests/test_steps.py
    - python -mpytest tests/pytests/test_utils.py

.nrun_test:
  extends: [.test]
  timeout: 2 hours
  artifacts:
    when: always
    paths:
      - RESULTS/*
    expire_in: 4 hours
  variables:
    sonata_path: configs/rat_sscxS1HL_V6/simulation_config.json
    bb5_ntasks: 32
  script:
    - source .ci/load.sh
    - source .ci/test.sh

integration_tests:
  extends: [.test]
  timeout: 10 minutes
  variables:
    bb5_duration: "00:10:00"
    bb5_ntasks: 2
  script:
    - source .ci/load.sh
    - rm -rf cache && srun --overlap -n 2 python tests/integration_tests/test_connect_ndam2steps.py
    - rm -rf cache && srun --overlap -n 2 python tests/integration_tests/test_ndam2steps_sync.py

.dualrun_test:
  extends: [.nrun_test]
  timeout: 2 hours
  variables:
    with_steps: 1
    with_metabolism: 0
    with_bloodflow: 0
    # Shortened time for CI
    mr_sim_end: 200

dualrun_test 1/16:
  extends: [.dualrun_test]
  variables:
    bb5_ntasks: 1
    # Shortened time for CI
    mr_sim_end: 200

dualrun_test 2/16:
  extends: [.dualrun_test]
  variables:
    bb5_ntasks: 2

dualrun_test 16/16:
  extends: [.dualrun_test]
  variables:
    bb5_ntasks: 16

nrun_[steps, metab, bf]:
  extends: [.nrun_test]
  variables:
    # Shortened time for CI. Here we just want to check that everything runs 
    # for a couple of syncs (every 100 ms atm). 
    # There are some accumulation problems when steps is not involved and metab fails on his own. 
    mr_sim_end: 200
  parallel:
    matrix:
    - with_steps: [0, 1]
      with_metabolism: [0, 1]
      with_bloodflow: [0, 1]
  rules:
    - if: $with_steps != "1" || $with_metabolism != "1" || $with_bloodflow != "1"

quadrun_test:
  extends: [.nrun_test]

